{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI08_lab_2018195014.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reccos7/AI_Class/blob/main/AI08_lab_2018195014.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkkZZLnkM2w5"
      },
      "source": [
        "# AI 08 Hymenoptera\n",
        "\n",
        "> 학번: 2018195014\n",
        ">\n",
        "> 이름: 이민재\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "destLyXRM2w7"
      },
      "source": [
        "# 8.1\n",
        "\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzdpqMzxM2w-"
      },
      "source": [
        "# 8.2\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')          \n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    \n",
        "print('device:', device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHvnJ1Q-M2xB"
      },
      "source": [
        "### Hyperparameters\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2m0d9ZAM2xB"
      },
      "source": [
        "# 8.3 하이퍼파라미터\n",
        "\n",
        "num_epochs = 30\n",
        "num_classes = 2\n",
        "batch_size = 4\n",
        "learning_rate = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EGLUfOSM2xD"
      },
      "source": [
        "### Load dataset\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZsVsMiQA0yR"
      },
      "source": [
        "# 8.4 Hymenoptera 데이터셋 다운로드\n",
        "\n",
        "!wget -O 'hymenoptera_data.zip' https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
        "!unzip 'hymenoptera_data.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJRtdHrtA0yT"
      },
      "source": [
        "# 8.5\n",
        "\n",
        "# Training을 위한 데이터 확장과 데이터셋 정규화\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),  # 랜덤 리사이즈 후 크롭\n",
        "        transforms.RandomHorizontalFlip(),  # 좌우반전\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "# Test를 위해서는 데이터셋 정규화만\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "        transforms.Resize(256),             # 리사이즈\n",
        "        transforms.CenterCrop(224),         # 가운데 크롭\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJrQkkiWM2xE"
      },
      "source": [
        "# 8.6\n",
        "\n",
        "# ImageFolder를 사용하여 폴더 안에 있는 이미지들을 데이터셋으로 사용\n",
        "\n",
        "train_dataset = datasets.ImageFolder( 'hymenoptera_data/train', train_transforms)\n",
        "test_dataset = datasets.ImageFolder( 'hymenoptera_data/val', test_transforms)\n",
        "\n",
        "train_loader = DataLoader( train_dataset, batch_size=batch_size, shuffle=True )\n",
        "test_loader = DataLoader( test_dataset, batch_size=batch_size, shuffle=True )\n",
        "\n",
        "# 분류 클래스 2개: ants, bees\n",
        "\n",
        "class_names = train_dataset.classes\n",
        "print(class_names)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-9T_HTEhJaN"
      },
      "source": [
        "### Preview data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIIiTfuwhecC"
      },
      "source": [
        "# 8.7 데이터 미리보기\n",
        "\n",
        "def convert_to_imshow_format(image):\n",
        "    # from 3 x Height x Width to Height x Width x 3\n",
        "    image = image.numpy().transpose(1,2,0)\n",
        "\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    \n",
        "    # convert back to [0,1] range from [-1,1] range\n",
        "    image = image * std + mean\n",
        "    image = np.clip(image, 0, 1)\n",
        "    \n",
        "    return image\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "images, labels = images[:6], labels[:6]\n",
        "\n",
        "fig, axes = plt.subplots(1, len(images), figsize=(14,4))\n",
        "for idx, image in enumerate(images):\n",
        "    axes[idx].imshow(convert_to_imshow_format(image))\n",
        "    axes[idx].set_title(class_names[labels[idx]])\n",
        "    axes[idx].set_xticks([])\n",
        "    axes[idx].set_yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O10KVzWYM2xG"
      },
      "source": [
        "### Progress monitor\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTX3NK7-M2xG"
      },
      "source": [
        "# 8.8\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "# Custom IPython progress bar for training\n",
        "class ProgressMonitor(object):\n",
        "    \n",
        "    tmpl = \"\"\"\n",
        "        <table style=\"width: 100%;\">\n",
        "            <tbody>\n",
        "                <tr>\n",
        "                    <td style=\"width: 30%;\">\n",
        "                     <b>Epoch: {epoch}/{num_epochs} Loss: {loss:0.4f}</b> &nbsp&nbsp&nbsp {value} / {length}\n",
        "                    </td>\n",
        "                    <td style=\"width: 70%;\">\n",
        "                        <progress value='{value}' max='{length}', style='width: 100%'>{value}</progress>\n",
        "                    </td>\n",
        "                </tr>\n",
        "            </tbody>\n",
        "        </table>        \n",
        "        \"\"\"\n",
        "\n",
        "    def __init__(self, length):\n",
        "        self.length = length\n",
        "        self.count = 0\n",
        "        self.display = display(self.html(0, 0, 0, 0), display_id=True)\n",
        "        \n",
        "    def html(self, count, loss, epoch, num_epochs):\n",
        "        return HTML(self.tmpl.format(length=self.length, value=count, loss=loss, epoch=epoch, num_epochs=num_epochs))\n",
        "        \n",
        "    def update(self, epoch, num_epochs, count, loss):\n",
        "        self.count += count\n",
        "        self.display.update(self.html(self.count, loss, epoch, num_epochs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2z3X8Yx7M2xI"
      },
      "source": [
        "### Finetuning the convnet\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9aJFEyiPmYh"
      },
      "source": [
        "# Resnet18 구조 출력\n",
        "model_ft = models.resnet18(pretrained=True)\n",
        "\n",
        "print(model_ft)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhK3lgtIM2xJ"
      },
      "source": [
        "# 8.9 Finetuning the ConvNet\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoBgCFtMl6xI"
      },
      "source": [
        "# 8.10 ConvNet as Fixed feature extractor\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQyAm_yWM2xS"
      },
      "source": [
        "### Train\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXq8-IvNM2xT"
      },
      "source": [
        "# 8.11 Train\n",
        "\n",
        "def train(epoch, num_epochs, model, optimizer, scheduler):\n",
        "\n",
        "    # train phase\n",
        "    model.train()\n",
        "    \n",
        "    # create a progress bar\n",
        "    batch_loss_list = []\n",
        "    progress = ProgressMonitor(length=len(train_dataset))\n",
        "\n",
        "    for batch, target in train_loader:\n",
        "        # Move the training data to the GPU\n",
        "        batch, target = batch.to(device), target.to(device)\n",
        "\n",
        "        # forward propagation\n",
        "        output = model( batch )\n",
        "\n",
        "        # calculate the loss\n",
        "        loss = loss_func( output, target )\n",
        "        \n",
        "        # clear previous gradient computation\n",
        "        optimizer.zero_grad()\n",
        " \n",
        "        # backpropagate to compute gradients\n",
        "        loss.backward()\n",
        " \n",
        "        # update model weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # update progress bar\n",
        "        batch_loss_list.append(loss.item())\n",
        "        progress.update(epoch, num_epochs, batch.shape[0], sum(batch_loss_list)/len(batch_loss_list) )\n",
        "\n",
        "    # 스케쥴러의 스텝을 증가 - 때가 되면 학습률 변경\n",
        "    if scheduler:\n",
        "        scheduler.step()\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKkLYuWkM2xU"
      },
      "source": [
        "# 8.12 Test\n",
        "\n",
        "def test(model):\n",
        "    # test phase\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    \n",
        "    # We don't need gradients for test, so wrap in \n",
        "    # no_grad to save memory\n",
        "    with torch.no_grad():\n",
        "        for batch, target in test_loader:\n",
        "            # Move the training batch to the GPU\n",
        "            batch, target = batch.to(device), target.to(device)\n",
        "\n",
        "            # forward propagation\n",
        "            output = model( batch )\n",
        "\n",
        "            # get prediction\n",
        "            output = torch.argmax(output, 1)\n",
        "\n",
        "            # accumulate correct number\n",
        "            correct += (output == target).sum().item()\n",
        "\n",
        "    # Calculate test accuracy    \n",
        "    acc = 100 * float(correct) / len(test_dataset) \n",
        "    print( 'Test Acc: {}/{} ({:.2f}%)'.format( correct, len(test_dataset), acc ) )  \n",
        "    \n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZR-CkDGAM2xW"
      },
      "source": [
        "# 8.13\n",
        "\n",
        "since = time.time()\n",
        "\n",
        "# initialize the best weights\n",
        "best_model_weights = copy.deepcopy( model_ft.state_dict() )\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # train\n",
        "    train(epoch+1, num_epochs, model_ft, optimizer_ft, lr_scheduler_ft )\n",
        "    # test\n",
        "    acc = test(model_ft)\n",
        "\n",
        "    # update the best weights\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        best_model_weights = copy.deepcopy( model_ft.state_dict() )\n",
        "\n",
        "# load the best weights\n",
        "model_ft.load_state_dict( best_model_weights )\n",
        "\n",
        "# summary\n",
        "time_elapsed = time.time() - since\n",
        "print('Training completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "print('Best test accuracy: {:4f}'.format(best_acc))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnCMAkW9gQBR"
      },
      "source": [
        "# 8.14\n",
        "\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(test_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(1, num_images, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                ax.imshow( convert_to_imshow_format(inputs.cpu().data[j]) )\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "        \n",
        "\n",
        "visualize_model(model_ft)        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK_7wufmthzs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
